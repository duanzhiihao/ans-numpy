{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision.transforms.functional as tvf\n",
    "\n",
    "from compressai.zoo.image import mbt2018_mean\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed comparsion for CompressAI models\n",
    "\n",
    "**Note:** this speed comparison includes the time to run neural network forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_kodak(model, verbose=None):\n",
    "    model = model.to(device).eval()\n",
    "    model.update(force=True)\n",
    "\n",
    "    img_paths = list(Path('~/datasets/kodak').expanduser().rglob('*.png'))\n",
    "    assert len(img_paths) == 24\n",
    "\n",
    "    metrics = defaultdict(float)\n",
    "    pbar = tqdm(img_paths, ascii=True, ncols=96, desc=f'{verbose}: ') if verbose else img_paths\n",
    "    for impath in pbar:\n",
    "        im = tvf.to_tensor(Image.open(impath).convert('RGB')).to(device).unsqueeze(0)\n",
    "\n",
    "        enc_begin = time.time()\n",
    "        compressed = model.compress(im)\n",
    "        enc_end = time.time()\n",
    "        outputs = model.decompress(compressed['strings'], compressed['shape'])\n",
    "        dec_end = time.time()\n",
    "\n",
    "        im_hat = outputs['x_hat']\n",
    "\n",
    "        # encoding and decoding time\n",
    "        metrics['enc-time'] += enc_end - enc_begin\n",
    "        metrics['dec-time'] += dec_end - enc_end\n",
    "\n",
    "        # estimate bpp and compute RGB PSNR\n",
    "        num_bits = sys.getsizeof(pickle.dumps(compressed['strings'])) * 8\n",
    "        bpp = num_bits / float(im.shape[2] * im.shape[3])\n",
    "        psnr = -10.0 * (im - im_hat).square().mean().log10().item()\n",
    "        # print(f'{impath.name}: PSNR={psnr:.2f}, BPP={bpp:.4f}')\n",
    "        metrics['estimated-bpp'] += bpp\n",
    "        metrics['rgb-psnr'] += psnr\n",
    "\n",
    "    if verbose:\n",
    "        for k, v in metrics.items():\n",
    "            if 'time' in k:\n",
    "                print(f'{k}: {v/24:.6f} s')\n",
    "            else:\n",
    "                print(f'{k}: {v/24:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CompressAI: 100%|###############################################| 24/24 [00:01<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc-time: 0.025475 s\n",
      "dec-time: 0.028343 s\n",
      "estimated-bpp: 0.1253\n",
      "rgb-psnr: 27.6996\n",
      "================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This repo: 100%|################################################| 24/24 [00:00<00:00, 24.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc-time: 0.010922 s\n",
      "dec-time: 0.019145 s\n",
      "estimated-bpp: 0.1253\n",
      "rgb-psnr: 27.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('='*96)\n",
    "model = mbt2018_mean(quality=1, pretrained=True)\n",
    "test_on_kodak(model, verbose=None) # warmup\n",
    "test_on_kodak(model, verbose='CompressAI')\n",
    "\n",
    "print('='*96)\n",
    "from compressai_models import MyGaussianConditional\n",
    "model.gaussian_conditional = MyGaussianConditional(None)\n",
    "test_on_kodak(model, verbose='This repo')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp311pt24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
